# Twitter - Data Mining, Assessing, Cleaning and Visualizating
In this module Tweeter data is  gathered/mined, assessed and cleaned. For that purpose a Python notebook is used. The twitter API is used to collect tweets which are later cleaned up. Information about the  data collected is then presented in graphical form.

## Getting Started

Fork or Clone the project to own GitHub repository. Use this code to mine Twitter Data using their API. Adapt to what it needed from the Json file retrieved from twitter. 

### Prerequisites

Python Jupyter Notebooks are essential for these project. Also any package that are shown on the first lines of the main project file wrangle_report.ipynb

### Installing

Download the following essential files:
- wrangle_report.ipynb
- dog_breed_stats.csv
- twitter_archive_master.csv

Create Twitter API Keys [here](https://developer.twitter.com/en/docs/basics/authentication/guides/access-tokens)

After that, the code can be run as a stand alone. It will mine all tweets from the WeRateDogs accounts. This information is then cleaned
and presented through visualizations and text.

Although the whole notebook is only factual about this page, WeRateDogs, the code part about fetching the Json file for the Twitter API can be applied to any other Twitter account. As well as all the techniques employed for data wrangling and cleaning.

## Built With

* [Jupyter Notebooks](http://jupyter.org/)

## Contributing

Please read [CONTRIBUTING.md](https://gist.github.com/PurpleBooth/b24679402957c63ec426) for details on our code of conduct, and the process for submitting pull requests to us.

## Versioning

We use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/your/project/tags). 

## Authors

* **Alexandre Campino** - *Initial work* 

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details

## Acknowledgments

* Udacity Lessons
* Stack Overflow
* GitHub Repositories
