# Twitter - Data Mining, Assessing, Cleaning and Visualizating
In this module Tweeter data is  gathered/mined, assessed and cleaned. For that purpose a Python notebook is used. The twitter API is used to collect tweets which are later cleaned up. Information about the  data collected is then presented in graphical form.

## Getting Started

Fork or Clone the project to your own Git. 

### Prerequisites

Python Jupyter Notebooks are essential for these project. Also any package that are shown on the first lines of the main project file wrangle_report.ipynb

### Installing

Download the following essential files:
- wrangle_report.ipynb
- dog_breed_stats.csv
- twitter_archive_master.csv

Create Twitter API Keys [here](https://developer.twitter.com/en/docs/basics/authentication/guides/access-tokens)


## Built With

* [Jupyter Notebooks](http://jupyter.org/)

## Contributing

Please read [CONTRIBUTING.md](https://gist.github.com/PurpleBooth/b24679402957c63ec426) for details on our code of conduct, and the process for submitting pull requests to us.

## Versioning

We use [SemVer](http://semver.org/) for versioning. For the versions available, see the [tags on this repository](https://github.com/your/project/tags). 

## Authors

* **Alexandre Campino** - *Initial work* 

## License

This project is licensed under the MIT License - see the [LICENSE.md](LICENSE.md) file for details

## Acknowledgments

* Udacity Lessons
* Stack Overflow
* GitHub Repositories
